import streamlit as st
import numpy as np
import joblib
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os

# D√©sactiver les warnings TensorFlow
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

# Importer Keras/TensorFlow avant de charger les mod√®les
try:
    import tensorflow as tf
    tf.get_logger().setLevel('ERROR')
    import keras
except ImportError:
    pass

# Classe wrapper pour le mod√®le SVM personnalis√©
class CustomSVMModel:
    """Wrapper pour un mod√®le SVM personnalis√© avec poids w et biais b"""
    def __init__(self, w, b):
        self.w = np.array(w)
        self.b = float(b)
    
    def predict(self, X):
        """Pr√©diction binaire : 0 ou 1"""
        scores = np.dot(X, self.w) + self.b
        return (scores >= 0).astype(int)
    
    def predict_proba(self, X):
        """Probabilit√©s : utilise une sigmo√Øde pour convertir les scores en probabilit√©s"""
        scores = np.dot(X, self.w) + self.b
        prob_maligne = 1 / (1 + np.exp(-scores))
        prob_benigne = 1 - prob_maligne
        return np.column_stack([prob_benigne, prob_maligne])

# Configuration de la page
st.set_page_config(
    page_title="Comparaison des Mod√®les - Sant√© Plus",
    page_icon="üìä",
    layout="wide"
)

# Chargement du CSS
def load_css():
    try:
        with open("style.css") as f:
            st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)
    except:
        pass

load_css()

# =========================
# Bouton de retour
# =========================
col_back, col_title = st.columns([1, 5])
with col_back:
    if st.button("‚Üê Retour", use_container_width=True):
        st.switch_page("pages/01_Accueil.py")

with col_title:
    st.markdown("""
    <div style="margin-top: 0.5rem;">
        <h1 style="color: #1f77b4; margin-bottom: 0.5rem;">üìä Comparaison des Mod√®les</h1>
    </div>
    """, unsafe_allow_html=True)

# =========================
# Description
# =========================
st.markdown("""
<div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
            padding: 1.5rem; border-radius: 12px; color: white; margin-bottom: 2rem;">
    <p style="font-size: 1.05rem; line-height: 1.8; margin: 0;">
        Comparez les pr√©dictions de <strong>tous les mod√®les</strong> avec les m√™mes caract√©ristiques.
        <br>Cette page vous permet d'√©valuer la coh√©rence et les diff√©rences entre les diff√©rents algorithmes de Machine Learning.
    </p>
</div>
""", unsafe_allow_html=True)

# =========================
# Chargement de tous les mod√®les
# =========================
@st.cache_resource
def load_all_models():
    """Charge tous les mod√®les et le scaler"""
    try:
        # S'assurer que Keras/TensorFlow sont import√©s avant de charger les mod√®les
        try:
            import tensorflow as tf
            tf.get_logger().setLevel('ERROR')
            import keras
        except ImportError:
            pass
        
        scaler = joblib.load("models/scaler.pkl")
        
        # Linear Regression
        lin_reg = joblib.load("models/linear_regression.pkl")
        
        # GRU-SVM (n√©cessite Keras)
        try:
            gru_svm_data = joblib.load("models/gru_svm.pkl")
            if isinstance(gru_svm_data, dict):
                gru_svm_model = gru_svm_data.get("svm", gru_svm_data.get("model", None))
            else:
                gru_svm_model = gru_svm_data
        except Exception as e:
            st.warning(f"Erreur lors du chargement de GRU-SVM : {e}")
            gru_svm_model = None
        
        # MLP (n√©cessite Keras)
        try:
            mlp_model = joblib.load("models/MLP.pkl")
        except Exception as e:
            st.warning(f"Erreur lors du chargement de MLP : {e}")
            mlp_model = None
        
        # Softmax
        try:
            softmax_model = joblib.load("models/softmax.pkl")
        except Exception as e:
            st.warning(f"Erreur lors du chargement de Softmax : {e}")
            softmax_model = None
        
        # k-NN
        knn_model = joblib.load("models/knn.pkl")
        
        # SVM - peut √™tre un mod√®le personnalis√© avec w et b
        try:
            svm_data = joblib.load("models/svm.pkl")
            if isinstance(svm_data, dict):
                if 'w' in svm_data and 'b' in svm_data:
                    # Mod√®le SVM personnalis√©
                    svm_model = CustomSVMModel(svm_data['w'], svm_data['b'])
                else:
                    # Essayer d'extraire un mod√®le scikit-learn
                    svm_model = None
                    for key in ["svm", "model", "classifier", "svm_model", "estimator"]:
                        if key in svm_data and hasattr(svm_data[key], 'predict'):
                            svm_model = svm_data[key]
                            break
                    if svm_model is None:
                        for key, value in svm_data.items():
                            if hasattr(value, 'predict') and not isinstance(value, dict):
                                svm_model = value
                                break
            else:
                svm_model = svm_data if hasattr(svm_data, 'predict') else None
        except Exception as e:
            st.warning(f"Erreur lors du chargement de SVM : {e}")
            svm_model = None
        
        return {
            "scaler": scaler,
            "Linear Regression": lin_reg,
            "GRU-SVM": gru_svm_model,
            "MLP": mlp_model,
            "Softmax Regression": softmax_model,
            "k-NN": knn_model,
            "SVM": svm_model
        }
    except Exception as e:
        # Ne pas arr√™ter compl√®tement, retourner ce qui a pu √™tre charg√©
        st.warning(f"‚ö†Ô∏è Certains mod√®les n'ont pas pu √™tre charg√©s : {e}")
        # Retourner au moins le scaler et les mod√®les de base
        return {
            "scaler": scaler if 'scaler' in locals() else None,
            "Linear Regression": lin_reg if 'lin_reg' in locals() else None,
            "GRU-SVM": gru_svm_model if 'gru_svm_model' in locals() else None,
            "MLP": mlp_model if 'mlp_model' in locals() else None,
            "Softmax Regression": softmax_model if 'softmax_model' in locals() else None,
            "k-NN": knn_model if 'knn_model' in locals() else None,
            "SVM": svm_model if 'svm_model' in locals() else None
        }

models = load_all_models()
scaler = models.get("scaler")
if scaler is None:
    st.error("‚ùå Impossible de charger le scaler. L'application ne peut pas fonctionner.")
    st.stop()

# =========================
# Formulaire d'entr√©e
# =========================
st.markdown("### üî¢ Entrer les caract√©ristiques de la tumeur")
st.markdown("Remplissez les 22 caract√©ristiques morphologiques ci-dessous :")

with st.form("comparison_form"):
    st.markdown("#### Caract√©ristiques moyennes (Mean)")
    col1, col2, col3 = st.columns(3)

    with col1:
        radius_mean = st.number_input("Radius Mean", min_value=0.0, value=0.0, step=0.1, format="%.2f", help="Rayon moyen des cellules")
        texture_mean = st.number_input("Texture Mean", min_value=0.0, value=0.0, step=0.1, format="%.2f", help="Texture moyenne")
        area_mean = st.number_input("Area Mean", min_value=0.0, value=0.0, step=1.0, format="%.2f", help="Surface moyenne")
        smoothness_mean = st.number_input("Smoothness Mean", min_value=0.0, value=0.0, step=0.001, format="%.4f", help="Lissage moyen")

    with col2:
        compactness_mean = st.number_input("Compactness Mean", min_value=0.0, value=0.0, step=0.001, format="%.4f", help="Compacit√© moyenne")
        concavity_mean = st.number_input("Concavity Mean", min_value=0.0, value=0.0, step=0.001, format="%.4f", help="Concavit√© moyenne")
        concave_points_mean = st.number_input("Concave Points Mean", min_value=0.0, value=0.0, step=0.001, format="%.4f", help="Points concaves moyens")
        symmetry_mean = st.number_input("Symmetry Mean", min_value=0.0, value=0.0, step=0.001, format="%.4f", help="Sym√©trie moyenne")

    with col3:
        fractal_dimension_mean = st.number_input("Fractal Dimension Mean", min_value=0.0, value=0.0, step=0.001, format="%.4f", help="Dimension fractale moyenne")
        radius_se = st.number_input("Radius SE", min_value=0.0, value=0.0, step=0.1, format="%.2f", help="Rayon (erreur standard)")
        area_se = st.number_input("Area SE", min_value=0.0, value=0.0, step=1.0, format="%.2f", help="Surface (erreur standard)")
        compactness_se = st.number_input("Compactness SE", min_value=0.0, value=0.0, step=0.001, format="%.4f", help="Compacit√© (erreur standard)")

    st.markdown("#### Caract√©ristiques d'erreur standard (SE)")
    col4, col5, col6 = st.columns(3)

    with col4:
        concavity_se = st.number_input("Concavity SE", min_value=0.0, value=0.0, step=0.001, format="%.4f", help="Concavit√© (erreur standard)")
        concave_points_se = st.number_input("Concave Points SE", min_value=0.0, value=0.0, step=0.001, format="%.4f", help="Points concaves (erreur standard)")

    st.markdown("#### Caract√©ristiques les plus d√©favorables (Worst)")
    col7, col8, col9 = st.columns(3)

    with col7:
        radius_worst = st.number_input("Radius Worst", min_value=0.0, value=0.0, step=0.1, format="%.2f", help="Rayon le plus d√©favorable")
        texture_worst = st.number_input("Texture Worst", min_value=0.0, value=0.0, step=0.1, format="%.2f", help="Texture la plus d√©favorable")
        area_worst = st.number_input("Area Worst", min_value=0.0, value=0.0, step=1.0, format="%.2f", help="Surface la plus d√©favorable")

    with col8:
        smoothness_worst = st.number_input("Smoothness Worst", min_value=0.0, value=0.0, step=0.001, format="%.4f", help="Lissage le plus d√©favorable")
        compactness_worst = st.number_input("Compactness Worst", min_value=0.0, value=0.0, step=0.001, format="%.4f", help="Compacit√© la plus d√©favorable")
        concavity_worst = st.number_input("Concavity Worst", min_value=0.0, value=0.0, step=0.001, format="%.4f", help="Concavit√© la plus d√©favorable")

    with col9:
        concave_points_worst = st.number_input("Concave Points Worst", min_value=0.0, value=0.0, step=0.001, format="%.4f", help="Points concaves les plus d√©favorables")
        symmetry_worst = st.number_input("Symmetry Worst", min_value=0.0, value=0.0, step=0.001, format="%.4f", help="Sym√©trie la plus d√©favorable")

    col_submit, _, _ = st.columns([1, 2, 2])
    with col_submit:
        submitted = st.form_submit_button("üîç Comparer tous les mod√®les", use_container_width=True, type="primary")

# =========================
# Pr√©dictions avec tous les mod√®les
# =========================
if submitted:
    # Construction du tableau d'entr√©e
    X_22 = np.array([[
        radius_mean, texture_mean, area_mean, smoothness_mean,
        compactness_mean, concavity_mean, concave_points_mean,
        symmetry_mean, fractal_dimension_mean,

        radius_se, area_se, compactness_se,
        concavity_se, concave_points_se,

        radius_worst, texture_worst, area_worst,
        smoothness_worst, compactness_worst,
        concavity_worst, concave_points_worst,
        symmetry_worst
    ]])

    # Standardisation
    X_scaled_22 = scaler.transform(X_22)

    # Dictionnaire pour stocker les r√©sultats
    results = {}

    # Pr√©diction avec chaque mod√®le
    with st.spinner("Calcul des pr√©dictions avec tous les mod√®les..."):
        # Linear Regression
        try:
            score = models["Linear Regression"].predict(X_scaled_22)[0]
            prob = max(0, min(1, score))  # Clamp entre 0 et 1
            pred = 1 if prob >= 0.5 else 0
            results["Linear Regression"] = {
                "probabilite": float(prob),  # Convertir en float Python
                "prediction": pred,
                "score": float(score),
                "type": "score"
            }
        except Exception as e:
            results["Linear Regression"] = {"error": str(e)}

        # GRU-SVM
        try:
            if models["GRU-SVM"] is None:
                results["GRU-SVM"] = {"error": "Mod√®le non charg√© (Keras requis)"}
            else:
                EXPECTED_FEATURES = 32
                n_missing = EXPECTED_FEATURES - X_scaled_22.shape[1]
                X_final = np.hstack([X_scaled_22, np.zeros((1, n_missing))])
                pred = models["GRU-SVM"].predict(X_final)[0]
                # Pour GRU-SVM, on n'a pas de probabilit√© directe, on utilise la pr√©diction
                prob = 0.8 if pred == 1 else 0.2  # Estimation
                results["GRU-SVM"] = {
                    "probabilite": float(prob),  # Convertir en float Python
                    "prediction": pred,
                    "type": "binary"
                }
        except Exception as e:
            results["GRU-SVM"] = {"error": str(e)}

        # MLP
        try:
            if models["MLP"] is None:
                results["MLP"] = {"error": "Mod√®le non charg√© (Keras requis)"}
            else:
                prob = models["MLP"].predict(X_scaled_22)[0][0]
                pred = 1 if prob >= 0.5 else 0
                results["MLP"] = {
                    "probabilite": float(prob),  # Convertir en float Python
                    "prediction": pred,
                    "type": "probability"
                }
        except Exception as e:
            results["MLP"] = {"error": str(e)}

        # Softmax Regression
        try:
            if models["Softmax Regression"] is None:
                results["Softmax Regression"] = {"error": "Mod√®le non charg√©"}
            else:
                prob = models["Softmax Regression"].predict(X_scaled_22)[0][1]
                pred = 1 if prob >= 0.5 else 0
                results["Softmax Regression"] = {
                    "probabilite": float(prob),  # Convertir en float Python
                    "prediction": pred,
                    "type": "probability"
                }
        except Exception as e:
            results["Softmax Regression"] = {"error": str(e)}

        # k-NN
        try:
            if models["k-NN"] is None:
                results["k-NN"] = {"error": "Mod√®le non charg√©"}
            else:
                prob = models["k-NN"].predict_proba(X_scaled_22)[0][1]
                pred = 1 if prob >= 0.5 else 0
                results["k-NN"] = {
                    "probabilite": float(prob),  # Convertir en float Python
                    "prediction": pred,
                    "type": "probability"
                }
        except Exception as e:
            results["k-NN"] = {"error": str(e)}

        # SVM
        try:
            if models["SVM"] is None:
                results["SVM"] = {"error": "Mod√®le non charg√©"}
            else:
                svm_model = models["SVM"]
                # Utiliser predict_proba si disponible
                if hasattr(svm_model, 'predict_proba'):
                    prob = svm_model.predict_proba(X_scaled_22)[0][1]
                else:
                    # Utiliser predict et estimer une probabilit√©
                    pred_result = svm_model.predict(X_scaled_22)
                    if isinstance(pred_result, np.ndarray):
                        y_pred_binary = int(pred_result[0])
                    else:
                        y_pred_binary = int(pred_result[0]) if hasattr(pred_result, '__getitem__') else int(pred_result)
                    prob = 0.8 if y_pred_binary == 1 else 0.2
                
                pred = 1 if prob >= 0.5 else 0
                results["SVM"] = {
                    "probabilite": float(prob),  # Convertir en float Python
                    "prediction": pred,
                    "type": "probability"
                }
        except Exception as e:
            results["SVM"] = {"error": str(e)}

    st.markdown("---")
    st.markdown("### üìä R√©sultats de la comparaison")

    # Affichage des erreurs s'il y en a
    errors_found = {name: r for name, r in results.items() if "error" in r}
    if errors_found:
        st.warning("‚ö†Ô∏è Certains mod√®les ont rencontr√© des erreurs :")
        for model_name, error_result in errors_found.items():
            st.error(f"**{model_name}** : {error_result['error']}")

    # Cr√©ation du DataFrame pour l'affichage
    comparison_data = []
    for model_name, result in results.items():
        if "error" not in result:
            comparison_data.append({
                "Mod√®le": model_name,
                "Probabilit√© de malignit√©": f"{result['probabilite']:.4f}",
                "Pr√©diction": "‚ö†Ô∏è Maligne" if result['prediction'] == 1 else "‚úÖ B√©nigne",
                "Confiance": "√âlev√©e" if abs(result['probabilite'] - 0.5) > 0.3 else "Moyenne" if abs(result['probabilite'] - 0.5) > 0.15 else "Faible"
            })

    if comparison_data:
        df = pd.DataFrame(comparison_data)
        
        # Affichage du tableau
        st.dataframe(df, use_container_width=True, hide_index=True)

        # Statistiques de consensus
        st.markdown("#### üìà Analyse de consensus")
        
        col_stat1, col_stat2, col_stat3, col_stat4 = st.columns(4)
        
        benign_count = sum(1 for r in results.values() if "error" not in r and r["prediction"] == 0)
        malign_count = sum(1 for r in results.values() if "error" not in r and r["prediction"] == 1)
        total_models = len([r for r in results.values() if "error" not in r])
        
        if total_models > 0:
            avg_prob = float(np.mean([r["probabilite"] for r in results.values() if "error" not in r]))  # Convertir en float Python
        else:
            avg_prob = 0.0
        
        with col_stat1:
            st.metric("Mod√®les test√©s", total_models)
        with col_stat2:
            if total_models > 0:
                st.metric("Pr√©dictions B√©nignes", benign_count, f"{benign_count/total_models*100:.1f}%")
            else:
                st.metric("Pr√©dictions B√©nignes", benign_count)
        with col_stat3:
            if total_models > 0:
                st.metric("Pr√©dictions Malignes", malign_count, f"{malign_count/total_models*100:.1f}%")
            else:
                st.metric("Pr√©dictions Malignes", malign_count)
        with col_stat4:
            st.metric("Probabilit√© moyenne", f"{avg_prob:.4f}")

        # Visualisation des probabilit√©s
        st.markdown("#### üìä Graphique de comparaison des probabilit√©s")
        
        fig, ax = plt.subplots(figsize=(12, 6))
        model_names = [r["Mod√®le"] for r in comparison_data]
        probs = [float(r["Probabilit√© de malignit√©"]) for r in comparison_data]
        colors = ['#d62728' if p >= 0.5 else '#2ca02c' for p in probs]
        
        bars = ax.barh(model_names, probs, color=colors, alpha=0.7)
        ax.axvline(x=0.5, color='gray', linestyle='--', linewidth=2, label='Seuil de d√©cision (0.5)')
        ax.set_xlabel('Probabilit√© de malignit√©', fontsize=12, fontweight='bold')
        ax.set_ylabel('Mod√®les', fontsize=12, fontweight='bold')
        ax.set_xlim(0, 1)
        ax.set_title('Comparaison des probabilit√©s de malignit√© par mod√®le', fontsize=14, fontweight='bold', pad=20)
        ax.legend()
        ax.grid(axis='x', alpha=0.3)
        
        # Ajouter les valeurs sur les barres
        for i, (bar, prob) in enumerate(zip(bars, probs)):
            ax.text(prob + 0.02, i, f'{prob:.3f}', va='center', fontweight='bold')
        
        plt.tight_layout()
        st.pyplot(fig)

        # Analyse de consensus
        if total_models > 0:
            st.markdown("#### ü§ù Consensus des mod√®les")
            
            if benign_count == total_models:
                st.success(f"‚úÖ **Consensus total** : Tous les {total_models} mod√®les pr√©disent une tumeur **B√âNIGNE**")
            elif malign_count == total_models:
                st.error(f"‚ö†Ô∏è **Consensus total** : Tous les {total_models} mod√®les pr√©disent une tumeur **MALIGNE**")
            else:
                consensus_rate = max(benign_count, malign_count) / total_models * 100
                st.warning(f"‚ö†Ô∏è **Consensus partiel** : {max(benign_count, malign_count)}/{total_models} mod√®les ({consensus_rate:.1f}%) sont d'accord")
                
                if benign_count > malign_count:
                    st.info(f"Majorit√© en faveur d'une tumeur **B√âNIGNE** ({benign_count}/{total_models} mod√®les)")
                else:
                    st.info(f"Majorit√© en faveur d'une tumeur **MALIGNE** ({malign_count}/{total_models} mod√®les)")

        # D√©tails par mod√®le
        st.markdown("#### üîç D√©tails par mod√®le")
        
        for model_name, result in results.items():
            if "error" not in result:
                col_detail1, col_detail2 = st.columns([2, 3])
                
                with col_detail1:
                    if result["prediction"] == 1:
                        st.markdown(f"""
                        <div style="background: linear-gradient(135deg, #ff9a9e 0%, #fecfef 100%); 
                                    padding: 1rem; border-radius: 10px; margin-bottom: 1rem;">
                            <h4 style="color: #d62728; margin: 0;">{model_name}</h4>
                            <p style="margin: 0.5rem 0 0 0; font-weight: bold;">‚ö†Ô∏è MALIGNE</p>
                        </div>
                        """, unsafe_allow_html=True)
                    else:
                        st.markdown(f"""
                        <div style="background: linear-gradient(135deg, #84fab0 0%, #8fd3f4 100%); 
                                    padding: 1rem; border-radius: 10px; margin-bottom: 1rem;">
                            <h4 style="color: #2ca02c; margin: 0;">{model_name}</h4>
                            <p style="margin: 0.5rem 0 0 0; font-weight: bold;">‚úÖ B√âNIGNE</p>
                        </div>
                        """, unsafe_allow_html=True)
                
                with col_detail2:
                    prob = float(result["probabilite"])  # Convertir en float Python pour Streamlit
                    st.progress(prob, text=f"Probabilit√© de malignit√© : {prob:.2%}")
            else:
                st.error(f"Erreur avec {model_name}: {result['error']}")

    st.info("‚ö†Ô∏è **Important** : Cette application est un outil d'aide √† la d√©cision et ne remplace pas un diagnostic m√©dical professionnel.")

